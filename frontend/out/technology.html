<!DOCTYPE html><!--HQWfSTQE2rrrrD4aL_oMY--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/8a30099612ed3301.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-1017649d66d1259f.js"/><script src="/_next/static/chunks/4bd1b696-c023c6e3521b1417.js" async=""></script><script src="/_next/static/chunks/255-293e44824f2ec188.js" async=""></script><script src="/_next/static/chunks/main-app-9b7a9014641bc585.js" async=""></script><script src="/_next/static/chunks/176-dbfe7d379a5d476e.js" async=""></script><script src="/_next/static/chunks/app/technology/page-accfad60cda3227b.js" async=""></script><title>prema.ai – Cognitive Director Video Agent</title><meta name="description" content="The world&#x27;s first autonomous Director AI for viral video editing."/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="bg-slate-950 text-slate-50 min-h-screen"><div hidden=""><!--$--><!--/$--></div><main class="min-h-screen bg-white text-slate-900 font-sans selection:bg-indigo-100 pb-20"><nav class="fixed top-0 left-0 right-0 z-[100] bg-white/90 backdrop-blur-md border-b border-slate-200"><div class="max-w-7xl mx-auto px-6 h-20 flex items-center justify-between"><a class="flex items-center gap-2 group" href="/"><div class="h-6 w-6 rounded-full bg-slate-900 group-hover:bg-indigo-600 transition-colors"></div><span class="font-semibold text-lg tracking-tight text-slate-900">prema.ai <span class="text-slate-400 font-normal">/ research</span></span></a><div class="hidden md:flex items-center gap-8"><a class="text-sm transition-colors text-slate-500 hover:text-slate-900" href="/product">Product</a><a class="text-sm transition-colors text-slate-900 font-semibold" href="/technology">Technology</a><a class="text-sm transition-colors text-slate-500 hover:text-slate-900" href="/research">Research</a><a class="text-sm transition-colors text-slate-500 hover:text-slate-900" href="/ethics">Ethics</a><a class="text-sm transition-colors text-slate-500 hover:text-slate-900" href="/about">About</a></div><div class="flex items-center gap-4"><a class="text-sm font-medium text-slate-600 hover:text-slate-900 transition-colors" href="/login">Log in</a><a class="px-5 py-2.5 bg-slate-900 text-white text-sm font-medium rounded-full hover:bg-black transition-colors shadow-lg shadow-slate-200" href="/setup">Launch Console</a></div></div></nav><section class="pt-40 pb-20 px-6"><div class="max-w-7xl mx-auto"><span class="text-xs font-mono text-indigo-600 mb-6 block tracking-widest uppercase">System Architecture<!-- --> -- 001</span><h1 class="text-5xl md:text-7xl font-semibold tracking-tighter text-slate-900 mb-8 max-w-4xl">The Agentic Stack</h1><p class="text-xl md:text-2xl text-slate-500 max-w-2xl leading-relaxed">Designed for reasoning, built for scale. A.V.E.A is a hybrid serverless system thinking in real-time.</p></div></section><section class="px-6 py-12 max-w-5xl mx-auto grid grid-cols-1 md:grid-cols-2 gap-12"><div class="space-y-6 p-8 bg-slate-50 rounded-2xl border border-slate-100"><div class="flex items-center gap-4"><div class="w-10 h-10 bg-white rounded-lg border border-slate-200 flex items-center justify-center shadow-sm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-cpu w-6 h-6 text-indigo-600"><rect width="16" height="16" x="4" y="4" rx="2"></rect><rect width="6" height="6" x="9" y="9" rx="1"></rect><path d="M15 2v2"></path><path d="M15 20v2"></path><path d="M2 15h2"></path><path d="M2 9h2"></path><path d="M20 15h2"></path><path d="M20 9h2"></path><path d="M9 2v2"></path><path d="M9 20v2"></path></svg></div><h3 class="text-xl font-medium text-slate-900">Multimodal Reasoning Engine</h3></div><p class="text-slate-600 leading-relaxed">At the core is Google&#x27;s Gemini 3.0 Pro. This LLM acts as the central reasoning unit, capable of understanding visual nuance, audio frequency, and complex user directives simultaneously.</p><div class="space-y-2 pt-4 border-t border-slate-200"><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>1M+ Token Context Window</div><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>Multimodal Input (Video/Audio)</div><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>Chain-of-Thought Planning</div></div></div><div class="space-y-6 p-8 bg-slate-50 rounded-2xl border border-slate-100"><div class="flex items-center gap-4"><div class="w-10 h-10 bg-white rounded-lg border border-slate-200 flex items-center justify-center shadow-sm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-server w-6 h-6 text-indigo-600"><rect width="20" height="8" x="2" y="2" rx="2" ry="2"></rect><rect width="20" height="8" x="2" y="14" rx="2" ry="2"></rect><line x1="6" x2="6.01" y1="6" y2="6"></line><line x1="6" x2="6.01" y1="18" y2="18"></line></svg></div><h3 class="text-xl font-medium text-slate-900">Serverless Execution Cloud</h3></div><p class="text-slate-600 leading-relaxed">The cognitive plan is executed by ephemeral Cloud Run instances. These isolated environments spin up to perform heavy lifting (FFmpeg rendering) and vanish immediately after, ensuring zero idle waste.</p><div class="space-y-2 pt-4 border-t border-slate-200"><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>Google Cloud Run (Gen 2)</div><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>Auto-scaling to Zero</div><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>2GiB+ RAM Isolated Containers</div></div></div><div class="space-y-6 p-8 bg-slate-50 rounded-2xl border border-slate-100"><div class="flex items-center gap-4"><div class="w-10 h-10 bg-white rounded-lg border border-slate-200 flex items-center justify-center shadow-sm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-database w-6 h-6 text-indigo-600"><ellipse cx="12" cy="5" rx="9" ry="3"></ellipse><path d="M3 5V19A9 3 0 0 0 21 19V5"></path><path d="M3 12A9 3 0 0 0 21 12"></path></svg></div><h3 class="text-xl font-medium text-slate-900">Perception &amp; Memory</h3></div><p class="text-slate-600 leading-relaxed">A.V.E.A maintains a semantic graph of every projected it edits. This long-term memory allows the agent to learn from feedback (&#x27;Stop cutting silence so tight&#x27;) and improve over time.</p><div class="space-y-2 pt-4 border-t border-slate-200"><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>Firestore Vector Store</div><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>Cloud Storage for 4K Assets</div><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>Semantic Scene Graphing</div></div></div><div class="space-y-6 p-8 bg-slate-50 rounded-2xl border border-slate-100"><div class="flex items-center gap-4"><div class="w-10 h-10 bg-white rounded-lg border border-slate-200 flex items-center justify-center shadow-sm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-lock w-6 h-6 text-indigo-600"><rect width="18" height="11" x="3" y="11" rx="2" ry="2"></rect><path d="M7 11V7a5 5 0 0 1 10 0v4"></path></svg></div><h3 class="text-xl font-medium text-slate-900">Enterprise-Grade Security</h3></div><p class="text-slate-600 leading-relaxed">Your footage is processed in a secure VPC. Raw assets are never used for model training. We strictly adhere to the Principle of Least Privilege for all agent actions.</p><div class="space-y-2 pt-4 border-t border-slate-200"><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>IAM Role-Based Access</div><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>No Client-Side Secrets</div><div class="flex items-center gap-2 text-sm text-slate-500 font-mono"><span class="w-1.5 h-1.5 rounded-full bg-indigo-400"></span>Ephemeral Processing Storage</div></div></div></section></main><!--$--><!--/$--><script src="/_next/static/chunks/webpack-1017649d66d1259f.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[9766,[],\"\"]\n3:I[8924,[],\"\"]\n4:I[1959,[],\"ClientPageRoot\"]\n5:I[5247,[\"176\",\"static/chunks/176-dbfe7d379a5d476e.js\",\"669\",\"static/chunks/app/technology/page-accfad60cda3227b.js\"],\"default\"]\n8:I[4431,[],\"OutletBoundary\"]\na:I[5278,[],\"AsyncMetadataOutlet\"]\nc:I[4431,[],\"ViewportBoundary\"]\ne:I[4431,[],\"MetadataBoundary\"]\nf:\"$Sreact.suspense\"\n11:I[7150,[],\"\"]\n:HL[\"/_next/static/css/8a30099612ed3301.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"HQWfSTQE2rrrrD4aL_oMY\",\"p\":\"\",\"c\":[\"\",\"technology\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"technology\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/8a30099612ed3301.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"bg-slate-950 text-slate-50 min-h-screen\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"technology\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L4\",null,{\"Component\":\"$5\",\"searchParams\":{},\"params\":{},\"promises\":[\"$@6\",\"$@7\"]}],null,[\"$\",\"$L8\",null,{\"children\":[\"$L9\",[\"$\",\"$La\",null,{\"promise\":\"$@b\"}]]}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],null],[\"$\",\"$Le\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$f\",null,{\"fallback\":null,\"children\":\"$L10\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n7:\"$0:f:0:1:2:children:2:children:1:props:children:0:props:params\"\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n9:null\n"])</script><script>self.__next_f.push([1,"b:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"prema.ai – Cognitive Director Video Agent\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"The world's first autonomous Director AI for viral video editing.\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"10:\"$b:metadata\"\n"])</script></body></html>